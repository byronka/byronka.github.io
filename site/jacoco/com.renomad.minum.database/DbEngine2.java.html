<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>DbEngine2.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">minum</a> &gt; <a href="index.source.html" class="el_package">com.renomad.minum.database</a> &gt; <span class="el_source">DbEngine2.java</span></div><h1>DbEngine2.java</h1><pre class="source lang-java linenums">package com.renomad.minum.database;

import com.renomad.minum.state.Context;

import java.io.IOException;
import java.nio.charset.StandardCharsets;
import java.nio.file.Files;
import java.nio.file.Path;
import java.util.*;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicLong;
import java.util.concurrent.locks.ReentrantLock;
import java.util.function.Function;
import java.util.stream.Stream;

import static com.renomad.minum.utils.Invariants.mustBeFalse;
import static com.renomad.minum.utils.Invariants.mustBeTrue;

/**
 * a memory-based disk-persisted database class.
 *
 * &lt;p&gt;
 *     Engine 2 is a database engine that improves on the performance from the first
 *     database provided by Minum. It does this by using different strategies for disk persistence.
 * &lt;/p&gt;
 * &lt;p&gt;
 *     The mental model of the previous Minum database has been an in-memory data
 *     structure in which every change is eventually written to its own file on disk for
 *     persistence.  Data changes affect just their relevant files.  The benefit of this approach is
 *     extreme simplicity. It requires very little code, relying as it does on the operating system's file capabilities.
 * &lt;/p&gt;
 * &lt;p&gt;
 *     However, there are two performance problems with this approach.  First is when the
 *     data changes are arriving at a high rate.  In that situation, the in-memory portion keeps up to date,
 *     but the disk portion may lag by minutes.  The second problem is start-up time.  When
 *     the database starts, it reads files into memory.  The database can read about 6,000
 *     files a second in the best case.  If there are a million data items, it would take
 *     about 160 seconds to load it into memory, which is far too long.
 * &lt;/p&gt;
 * &lt;p&gt;
 *      The new approach to disk persistence is to append each change to a file.  Append-only file
 *      changes can be very fast.  These append files are eventually consolidated into files
 *      partitioned by their index - data with indexes between 1 and 1000 go into one file, between
 *      1001 and 2000 go into another, and so on.
 *  &lt;/p&gt;
 *  &lt;p&gt;
 *      Startup is magnitudes faster by this approach.  What took the previous database 160 seconds
 *      to load requires only 2 seconds. Writes to disk are also faster. What would have taken
 *      several minutes to write should only take a few seconds now.
 *  &lt;/p&gt;
 *  &lt;p&gt;
 *      This new approach uses a different file structure than the previous. If it is
 *      desired to use the new engine on existing data, it is possible to convert the old
 *      data format to the new.  Construct an instance of the new engine, pointing
 *      at the same name as the previous, and it will convert the data.  If the previous
 *      call looked like this:
 *  &lt;/p&gt;
 *  &lt;code&gt;
 *  Db&lt;Photograph&gt; photoDb = context.getDb(&quot;photos&quot;, Photograph.EMPTY);
 *  &lt;/code&gt;
 *  &lt;p&gt;
 *  Then converting to the new database is just replacing it with the following
 *  line. &lt;b&gt;Please, backup your database before this change.&lt;/b&gt;
 *  &lt;/p&gt;
 *  &lt;p&gt;
 * &lt;code&gt;
 *     DbEngine2&lt;Photograph&gt; photoDb = context.getDb2(&quot;photos&quot;, Photograph.EMPTY);
 * &lt;/code&gt;
 *  &lt;/p&gt;
 *  &lt;p&gt;
 *     Once the new engine starts up, it will notice the old file structure and convert it
 *     over.  The methods and behaviors are mostly the same between the old and new engines, so the
 *     update should be straightforward.
 * &lt;/p&gt;
 * &lt;p&gt;
 *     (By the way, it *is* possible to convert back to the old file structure,
 *     by starting the database the old way again.  Just be aware that each time the
 *     files are converted, it takes longer than normal to start the database)
 * &lt;/p&gt;
 * &lt;p&gt;
 *     However, something to note is that using the old database is still fine in many cases,
 *     particularly for prototypes or systems which do not contain large amounts of data. If
 *     your system is working fine, there is no need to change things.
 * &lt;/p&gt;
 *
 * @param &lt;T&gt; the type of data we'll be persisting (must extend from {@link DbData})
 */
public final class DbEngine2&lt;T extends DbData&lt;?&gt;&gt; extends AbstractDb&lt;T&gt; {

    private final ReentrantLock loadDataLock;
    private final ReentrantLock consolidateLock;
    private final ReentrantLock writeLock;
    int maxLinesPerAppendFile;
    boolean hasLoadedData;
    final DatabaseAppender databaseAppender;
    private final DatabaseConsolidator databaseConsolidator;

    /**
     * Here we track the number of appends we have made.  Once it hits
     * a certain number, we will kick off a consolidation in a thread
     */
<span class="fc" id="L102">    final AtomicInteger appendCount = new AtomicInteger(0);</span>

    /**
     * Used to determine whether to kick off consolidation.  If it is
     * already running, we don't want to kick it off again. This would
     * only affect us if we are updating the database very fast.
     */
    boolean consolidationIsRunning;

    /**
     * Constructs an in-memory disk-persisted database.
     * Loading of data from disk happens at the first invocation of any command
     * changing or requesting data, such as {@link #write(DbData)}, {@link #delete(DbData)},
     * or {@link #values()}.  See the private method loadData() for details.
     * @param dbDirectory this uniquely names your database, and also sets the directory
     *                    name for this data.  The expected use case is to name this after
     *                    the data in question.  For example, &quot;users&quot;, or &quot;accounts&quot;.
     * @param context used to provide important state data to several components
     * @param instance an instance of the {@link DbData} object relevant for use in this database. Note
     *                 that each database (that is, each instance of this class), focuses on just one
     *                 data, which must be an implementation of {@link DbData}.
     */
    public DbEngine2(Path dbDirectory, Context context, T instance) {
<span class="fc" id="L125">        super(dbDirectory, context, instance);</span>

<span class="fc" id="L127">        this.databaseConsolidator = new DatabaseConsolidator(dbDirectory, context);</span>
        try {
<span class="fc" id="L129">            this.databaseAppender = new DatabaseAppender(dbDirectory, context);</span>
<span class="fc" id="L130">        } catch (IOException e) {</span>
<span class="fc" id="L131">            throw new DbException(&quot;Error while initializing DatabaseAppender in DbEngine2&quot;, e);</span>
<span class="fc" id="L132">        }</span>
<span class="fc" id="L133">        this.loadDataLock = new ReentrantLock();</span>
<span class="fc" id="L134">        this.consolidateLock = new ReentrantLock();</span>
<span class="fc" id="L135">        this.writeLock = new ReentrantLock();</span>
<span class="fc" id="L136">        this.maxLinesPerAppendFile = context.getConstants().maxAppendCount;</span>
<span class="fc" id="L137">    }</span>

    /**
     * Write data to the database.  Use an index of 0 to store new data, and a positive
     * non-zero value to update data.
     * &lt;p&gt;&lt;em&gt;
     *     Example of adding new data to the database:
     * &lt;/p&gt;&lt;/em&gt;
     * {@snippet :
     *          final var newSalt = StringUtils.generateSecureRandomString(10);
     *          final var hashedPassword = CryptoUtils.createPasswordHash(newPassword, newSalt);
     *          final var newUser = new User(0L, newUsername, hashedPassword, newSalt);
     *          userDb.write(newUser);
     * }
     * &lt;p&gt;&lt;em&gt;
     *     Example of updating data:
     * &lt;/p&gt;&lt;/em&gt;
     * {@snippet :
     *         // write the updated salted password to the database
     *         final var updatedUser = new User(
     *                 user().getIndex(),
     *                 user().getUsername(),
     *                 hashedPassword,
     *                 newSalt);
     *         userDb.write(updatedUser);
     * }
     *
     * @param newData the data we are writing
     * @return the data with its new index assigned.
     * @throws DbException if there is a failure to write
     */
    @Override
    public T write(T newData) {
<span class="fc bfc" id="L170" title="All 2 branches covered.">        if (newData.getIndex() &lt; 0) throw new DbException(&quot;Negative indexes are disallowed&quot;);</span>
        // load data if needed
<span class="fc bfc" id="L172" title="All 2 branches covered.">        if (!hasLoadedData) loadData();</span>

<span class="fc" id="L174">        writeLock.lock();</span>
        try {
<span class="fc" id="L176">            boolean newElementCreated = processDataIndex(newData);</span>
<span class="fc" id="L177">            writeToDisk(newData);</span>
<span class="fc" id="L178">            writeToMemory(newData, newElementCreated);</span>
<span class="fc" id="L179">        } catch (IOException ex) {</span>
<span class="fc" id="L180">           throw new DbException(&quot;failed to write data &quot; + newData, ex);</span>
        } finally {
<span class="fc" id="L182">            writeLock.unlock();</span>
        }

        // returning the data at this point is the most convenient
        // way users will have access to the new index of the data.
<span class="fc" id="L187">        return newData;</span>
    }


    private void writeToDisk(T newData) throws IOException {
<span class="fc" id="L192">        logger.logTrace(() -&gt; String.format(&quot;writing data to disk: %s&quot;, newData));</span>
<span class="fc" id="L193">        String serializedData = newData.serialize();</span>
<span class="fc bfc" id="L194" title="All 4 branches covered.">        mustBeFalse(serializedData == null || serializedData.isBlank(),</span>
                &quot;the serialized form of data must not be blank. &quot; +
                        &quot;Is the serialization code written properly? Our datatype: &quot; + emptyInstance);
<span class="fc" id="L197">        databaseAppender.appendToDatabase(DatabaseChangeAction.UPDATE, serializedData);</span>
<span class="fc" id="L198">        appendCount.incrementAndGet();</span>
<span class="fc" id="L199">        consolidateIfNecessary();</span>
<span class="fc" id="L200">    }</span>

    /**
     * If the append count is large enough, we will call the
     * consolidation method on the DatabaseConsolidator and
     * reset the append count to 0.
     */
    boolean consolidateIfNecessary() {
<span class="fc bfc" id="L208" title="All 4 branches covered.">        if (appendCount.get() &gt; maxLinesPerAppendFile &amp;&amp; !consolidationIsRunning) {</span>
<span class="fc" id="L209">            consolidateLock.lock(); // block threads here if multiple are trying to get in - only one gets in at a time</span>
            try {
<span class="fc" id="L211">                consolidateInnerCode();</span>
            } finally {
<span class="fc" id="L213">                consolidateLock.unlock();</span>
            }
<span class="fc" id="L215">            return true;</span>
        }
<span class="fc" id="L217">        return false;</span>
    }

    /**
     * This code is only called in production from {@link #consolidateIfNecessary()},
     * and is necessarily protected by mutex locks.  However, it is provided
     * here as its own method for ease of testing.
     */
    void consolidateInnerCode() {
<span class="fc bfc" id="L226" title="All 4 branches covered.">        if (appendCount.get() &gt; maxLinesPerAppendFile &amp;&amp; !consolidationIsRunning) {</span>
<span class="fc" id="L227">            context.getExecutorService().submit(() -&gt; {</span>
                try {
<span class="fc" id="L229">                    consolidationIsRunning = true;</span>
<span class="fc" id="L230">                    databaseConsolidator.consolidate();</span>
<span class="fc" id="L231">                    consolidationIsRunning = false;</span>
<span class="fc" id="L232">                } catch (Exception e) {</span>
<span class="fc" id="L233">                    logger.logAsyncError(() -&gt; &quot;Error during consolidation: &quot; + e);</span>
<span class="fc" id="L234">                }</span>
<span class="fc" id="L235">            });</span>
<span class="fc" id="L236">            appendCount.set(0);</span>
        }
<span class="fc" id="L238">    }</span>

    /**
     * Delete data
     * &lt;p&gt;&lt;em&gt;Example:&lt;/p&gt;&lt;/em&gt;
     * {@snippet :
     *      userDb.delete(user);
     * }
     * @param dataToDelete the data we are serializing and writing
     * @throws DbException if there is a failure to delete
     */
    @Override
    public void delete(T dataToDelete) {
        // load data if needed
<span class="fc bfc" id="L252" title="All 2 branches covered.">        if (!hasLoadedData) loadData();</span>

<span class="fc" id="L254">        writeLock.lock();</span>
        try {
<span class="fc" id="L256">            deleteFromDisk(dataToDelete);</span>
<span class="fc" id="L257">            deleteFromMemory(dataToDelete);</span>
<span class="fc" id="L258">        } catch (IOException ex) {</span>
<span class="fc" id="L259">            throw new DbException(&quot;failed to delete data &quot; + dataToDelete, ex);</span>
        } finally {
<span class="fc" id="L261">            writeLock.unlock();</span>
        }
<span class="fc" id="L263">    }</span>

    private void deleteFromDisk(T dataToDelete) throws IOException {
<span class="fc" id="L266">        logger.logTrace(() -&gt; String.format(&quot;deleting data from disk: %s&quot;, dataToDelete));</span>
<span class="fc" id="L267">        databaseAppender.appendToDatabase(DatabaseChangeAction.DELETE, dataToDelete.serialize());</span>
<span class="fc" id="L268">        appendCount.incrementAndGet();</span>
<span class="fc" id="L269">        consolidateIfNecessary();</span>
<span class="fc" id="L270">    }</span>


    /**
     * Tells the database to load its data into memory immediately rather
     * than wait for a command that would require data (like {@link #write(DbData)},
     * {@link #delete(DbData)}, or {@link #values()}). This may be valuable
     * in cases where the developer wants greater control over the timing - such
     * as getting the data loaded into memory immediately at program start.
     */
    private void loadDataFromDisk() throws IOException {
        // if we find the &quot;index.ddps&quot; file, it means we are looking at an old
        // version of the database.  Update it to the new version, and then afterwards
        // remove the old version files.
<span class="fc bfc" id="L284" title="All 2 branches covered.">        if (Files.exists(dbDirectory.resolve(&quot;index.ddps&quot;))) {</span>
<span class="fc" id="L285">            new DbFileConverter(context, dbDirectory).convertClassicFolderStructureToDbEngine2Form();</span>
        }

<span class="fc" id="L288">        fileUtils.makeDirectory(dbDirectory);</span>
        // if there are any remnant items in the current append-only file, move them
        // to a new file
<span class="fc" id="L291">        databaseAppender.saveOffCurrentDataToReadyFolder();</span>
<span class="fc" id="L292">        databaseAppender.flush();</span>

        // consolidate whatever files still exist in the append logs
<span class="fc" id="L295">        databaseConsolidator.consolidate();</span>

        // load the data into memory
<span class="fc" id="L298">        walkAndLoad(dbDirectory);</span>

<span class="fc bfc" id="L300" title="All 2 branches covered.">        if (data.isEmpty()) {</span>
<span class="fc" id="L301">            this.index = new AtomicLong(1);</span>
        } else {
<span class="fc" id="L303">            var initialIndex = Collections.max(data.keySet()) + 1L;</span>
<span class="fc" id="L304">            this.index = new AtomicLong(initialIndex);</span>
        }
<span class="fc" id="L306">    }</span>

    /**
     * Loops through each line of data in the consolidated data files,
     * converting each to its strongly-typed form and adding to the database
     */
    void walkAndLoad(Path dbDirectory) {
<span class="fc" id="L313">        List&lt;String&gt; consolidatedFiles = new ArrayList&lt;&gt;(</span>
<span class="fc" id="L314">                List.of(Objects.requireNonNull(dbDirectory.resolve(&quot;consolidated_data&quot;).toFile().list())));</span>

        // if there aren't any files, bail out
<span class="fc bfc" id="L317" title="All 2 branches covered.">        if (consolidatedFiles.isEmpty()) return;</span>

        // sort
<span class="fc" id="L320">        consolidatedFiles.sort(Comparator.comparingLong(DbEngine2::parseConsolidatedFileName));</span>

<span class="fc bfc" id="L322" title="All 2 branches covered.">        for (String fileName : consolidatedFiles) {</span>
<span class="fc" id="L323">            logger.logDebug(() -&gt; &quot;Processing database file: &quot; + fileName);</span>
<span class="fc" id="L324">            Path consolidatedDataFile = dbDirectory.resolve(&quot;consolidated_data&quot;).resolve(fileName);</span>

            // By using a lazy stream, we are able to read each item from the file into
            // memory without needing to read the whole file contents into memory at once,
            // thus avoiding requiring a great amount of memory
<span class="fc" id="L329">            try(Stream&lt;String&gt; fileStream = Files.lines(consolidatedDataFile, StandardCharsets.US_ASCII)) {</span>
<span class="fc" id="L330">                fileStream.forEach(line -&gt; readAndDeserialize(line, fileName));</span>
<span class="fc" id="L331">            } catch (Exception e) {</span>
<span class="fc" id="L332">                throw new DbException(e);</span>
<span class="fc" id="L333">            }</span>
<span class="fc" id="L334">        }</span>
<span class="fc" id="L335">    }</span>

    /**
     * Given a file like 1_to_1000 or 1001_to_2000, extract out the
     * beginning index (i.e. 1, or 1001).
     */
    static long parseConsolidatedFileName(String file) {
<span class="fc" id="L342">        int index = file.indexOf(&quot;_to_&quot;);</span>
<span class="fc bfc" id="L343" title="All 2 branches covered.">        if (index == -1) {</span>
<span class="fc" id="L344">            throw new DbException(&quot;Consolidated filename was invalid: &quot; + file);</span>
        }
<span class="fc" id="L346">        return Long.parseLong(file, 0, index, 10);</span>
    }

    /**
     * Converts a serialized string to a strongly-typed data structure
     * and adds it to the database.
     */
    void readAndDeserialize(String lineOfData, String fileName) {
        try {
            @SuppressWarnings(&quot;unchecked&quot;)
<span class="fc" id="L356">            T deserializedData = (T) emptyInstance.deserialize(lineOfData);</span>
<span class="fc bfc" id="L357" title="All 2 branches covered.">            mustBeTrue(deserializedData != null, &quot;deserialization of &quot; + emptyInstance +</span>
                    &quot; resulted in a null value. Was the serialization method implemented properly?&quot;);

            // put the data into the in-memory data structure
<span class="fc" id="L361">            data.put(deserializedData.getIndex(), deserializedData);</span>
<span class="fc" id="L362">            addToIndexes(deserializedData);</span>

<span class="fc" id="L364">        } catch (Exception e) {</span>
<span class="fc" id="L365">            throw new DbException(&quot;Failed to deserialize &quot; + lineOfData + &quot; with data (\&quot;&quot; + fileName + &quot;\&quot;). Caused by: &quot; + e);</span>
<span class="fc" id="L366">        }</span>
<span class="fc" id="L367">    }</span>


    /**
     * This is what loads the data from disk the
     * first time someone needs it.  Because it is
     * locked, only one thread can enter at
     * a time.  The first one in will load the data,
     * and the second will encounter a branch which skips loading.
     */
    @Override
    public void loadData() {
<span class="fc" id="L379">        loadDataLock.lock(); // block threads here if multiple are trying to get in - only one gets in at a time</span>
        try {
<span class="fc bfc" id="L381" title="All 2 branches covered.">            if (!hasLoadedData) {</span>
<span class="fc" id="L382">                loadDataFromDisk();</span>
            }
<span class="fc" id="L384">            hasLoadedData = true;</span>
<span class="fc" id="L385">        } catch (Exception ex) {</span>
<span class="fc" id="L386">            throw new DbException(&quot;Failed to load data from disk.&quot;, ex);</span>
        } finally {
<span class="fc" id="L388">            loadDataLock.unlock();</span>
        }
<span class="fc" id="L390">    }</span>

    /**
     * This method provides read capability for the values of a database.
     * &lt;br&gt;
     * The returned collection is a read-only view over the data, through {@link Collections#unmodifiableCollection(Collection)}
     *
     * &lt;p&gt;&lt;em&gt;Example:&lt;/em&gt;&lt;/p&gt;
     * {@snippet :
     * boolean doesUserAlreadyExist(String username) {
     *     return userDb.values().stream().anyMatch(x -&gt; x.getUsername().equals(username));
     * }
     * }
     */
    @Override
    public Collection&lt;T&gt; values() {
        // load data if needed
<span class="fc bfc" id="L407" title="All 2 branches covered.">        if (!hasLoadedData) loadData();</span>

<span class="fc" id="L409">        return Collections.unmodifiableCollection(data.values());</span>
    }

    @Override
    public boolean registerIndex(String indexName, Function&lt;T, String&gt; keyObtainingFunction) {
<span class="fc bfc" id="L414" title="All 2 branches covered.">        if (hasLoadedData) {</span>
<span class="fc" id="L415">            throw new DbException(&quot;This method must be run before the database loads data from disk.  Typically, &quot; +</span>
                    &quot;it should be run immediately after the database is created.  See this method's documentation&quot;);
        }
<span class="fc" id="L418">        return super.registerIndex(indexName, keyObtainingFunction);</span>
    }


    @Override
    public Collection&lt;T&gt; getIndexedData(String indexName, String key) {
        // load data if needed
<span class="fc bfc" id="L425" title="All 2 branches covered.">        if (!hasLoadedData) loadData();</span>
<span class="fc" id="L426">        return super.getIndexedData(indexName, key);</span>
    }

    /**
     * This command calls {@link DatabaseAppender#flush()}, which will
     * force any in-memory-buffered data to be written to disk.  This is
     * not commonly necessary to call for business purposes, but tests
     * may require it if you want to be absolutely sure the data is written
     * to disk at a particular moment.
     */
    public void flush() {
<span class="fc" id="L437">        this.databaseAppender.flush();</span>
<span class="fc" id="L438">    }</span>

    /**
     * This is here to match the contract of {@link Db}
     * but all it does is tell the interior file writer
     * to write its data to disk.
     */
    @Override
    public void stop() {
<span class="fc" id="L447">        flush();</span>
<span class="fc" id="L448">    }</span>

    /**
     * No real difference to {@link #stop()} but here
     * to have a similar contract to {@link Db}
     */
    @Override
    public void stop(int count, int sleepTime) {
<span class="fc" id="L456">        flush();</span>
<span class="fc" id="L457">    }</span>
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.12.202403310830</span></div></body></html>